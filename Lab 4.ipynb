{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": "     AGE  FEMALE  LOS  RACE  TOTCHG  APRDRG\n0     17       1    2   1.0    2660     560\n1     17       0    2   1.0    1689     753\n2     17       1    7   1.0   20060     930\n3     17       1    1   1.0     736     758\n4     17       1    1   1.0    1194     754\n..   ...     ...  ...   ...     ...     ...\n495    0       1    6   1.0    5881     636\n496    0       1    2   1.0    1171     640\n497    0       1    2   1.0    1171     640\n498    0       1    2   1.0    1086     640\n499    0       0    4   1.0    4931     640\n\n[500 rows x 6 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>AGE</th>\n      <th>FEMALE</th>\n      <th>LOS</th>\n      <th>RACE</th>\n      <th>TOTCHG</th>\n      <th>APRDRG</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>17</td>\n      <td>1</td>\n      <td>2</td>\n      <td>1.0</td>\n      <td>2660</td>\n      <td>560</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>17</td>\n      <td>0</td>\n      <td>2</td>\n      <td>1.0</td>\n      <td>1689</td>\n      <td>753</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>17</td>\n      <td>1</td>\n      <td>7</td>\n      <td>1.0</td>\n      <td>20060</td>\n      <td>930</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>17</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1.0</td>\n      <td>736</td>\n      <td>758</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>17</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1.0</td>\n      <td>1194</td>\n      <td>754</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>495</th>\n      <td>0</td>\n      <td>1</td>\n      <td>6</td>\n      <td>1.0</td>\n      <td>5881</td>\n      <td>636</td>\n    </tr>\n    <tr>\n      <th>496</th>\n      <td>0</td>\n      <td>1</td>\n      <td>2</td>\n      <td>1.0</td>\n      <td>1171</td>\n      <td>640</td>\n    </tr>\n    <tr>\n      <th>497</th>\n      <td>0</td>\n      <td>1</td>\n      <td>2</td>\n      <td>1.0</td>\n      <td>1171</td>\n      <td>640</td>\n    </tr>\n    <tr>\n      <th>498</th>\n      <td>0</td>\n      <td>1</td>\n      <td>2</td>\n      <td>1.0</td>\n      <td>1086</td>\n      <td>640</td>\n    </tr>\n    <tr>\n      <th>499</th>\n      <td>0</td>\n      <td>0</td>\n      <td>4</td>\n      <td>1.0</td>\n      <td>4931</td>\n      <td>640</td>\n    </tr>\n  </tbody>\n</table>\n<p>500 rows × 6 columns</p>\n</div>"
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#SUPERSED MACHINE LEARNING AND CROSS-VALIDATION\n",
    "#LAB 4\n",
    "\n",
    "import pandas as pd\n",
    "hospitalCost=pd.read_csv('hospitalData/HospitalCosts.csv')\n",
    "hospitalCost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "data": {
      "text/plain": "(500, 6)"
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#getting dimensions of the dataframe (rows/observations by columns)\n",
    "hospitalCost.shape"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "data": {
      "text/plain": "Index(['AGE', 'FEMALE', 'LOS', 'RACE', 'TOTCHG', 'APRDRG'], dtype='object')"
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#For future labs - need to determine dependent variables and independent variables\n",
    "\n",
    "#checking for column names\n",
    "hospitalCost.columns\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: numpy in /Users/lvngwtr/opt/anaconda3/lib/python3.9/site-packages (1.21.5)\r\n"
     ]
    },
    {
     "data": {
      "text/plain": "     AGE  FEMALE  LOS  RACE  TOTCHG  APRDRG\n0     17       1    2   1.0    2660     560\n1     17       0    2   1.0    1689     753\n2     17       1    7   1.0   20060     930\n3     17       1    1   1.0     736     758\n4     17       1    1   1.0    1194     754\n..   ...     ...  ...   ...     ...     ...\n495    0       1    6   1.0    5881     636\n496    0       1    2   1.0    1171     640\n497    0       1    2   1.0    1171     640\n498    0       1    2   1.0    1086     640\n499    0       0    4   1.0    4931     640\n\n[500 rows x 6 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>AGE</th>\n      <th>FEMALE</th>\n      <th>LOS</th>\n      <th>RACE</th>\n      <th>TOTCHG</th>\n      <th>APRDRG</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>17</td>\n      <td>1</td>\n      <td>2</td>\n      <td>1.0</td>\n      <td>2660</td>\n      <td>560</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>17</td>\n      <td>0</td>\n      <td>2</td>\n      <td>1.0</td>\n      <td>1689</td>\n      <td>753</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>17</td>\n      <td>1</td>\n      <td>7</td>\n      <td>1.0</td>\n      <td>20060</td>\n      <td>930</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>17</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1.0</td>\n      <td>736</td>\n      <td>758</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>17</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1.0</td>\n      <td>1194</td>\n      <td>754</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>495</th>\n      <td>0</td>\n      <td>1</td>\n      <td>6</td>\n      <td>1.0</td>\n      <td>5881</td>\n      <td>636</td>\n    </tr>\n    <tr>\n      <th>496</th>\n      <td>0</td>\n      <td>1</td>\n      <td>2</td>\n      <td>1.0</td>\n      <td>1171</td>\n      <td>640</td>\n    </tr>\n    <tr>\n      <th>497</th>\n      <td>0</td>\n      <td>1</td>\n      <td>2</td>\n      <td>1.0</td>\n      <td>1171</td>\n      <td>640</td>\n    </tr>\n    <tr>\n      <th>498</th>\n      <td>0</td>\n      <td>1</td>\n      <td>2</td>\n      <td>1.0</td>\n      <td>1086</td>\n      <td>640</td>\n    </tr>\n    <tr>\n      <th>499</th>\n      <td>0</td>\n      <td>0</td>\n      <td>4</td>\n      <td>1.0</td>\n      <td>4931</td>\n      <td>640</td>\n    </tr>\n  </tbody>\n</table>\n<p>500 rows × 6 columns</p>\n</div>"
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Lab notes from instructions\n",
    "\n",
    "# AGE will be the age of patient, FEMALE will be the gender it has only binary values 0/1, assuming 0 is Female and 1 is male. LOS is the Length of stay, RACE is the race of patient, TOTCHG is the total charge paid, and APRDRG is also another charge but the description of that column is not provided.  As promised earlier, I will give you the independent/dependent variables.\n",
    "# Dependent : LOS\n",
    "# Independent: AGE, TOTCHG, FEMALE, RACE,APRDRG\n",
    "\n",
    "\n",
    "#Checking to see which columns are numerical\n",
    "!pip install numpy\n",
    "import numpy as np\n",
    "hospitalCost.select_dtypes(np.number)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [
    {
     "data": {
      "text/plain": "AGE       0\nFEMALE    0\nLOS       0\nRACE      1\nTOTCHG    0\nAPRDRG    0\ndtype: int64"
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#results shows that all columns are numerical, so no need to convert the categorical values to numerical\n",
    "\n",
    "\n",
    "#Now checking to see if any of the columns have null values or NA\n",
    "hospitalCost.isnull().sum()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [
    {
     "data": {
      "text/plain": "     AGE  FEMALE  LOS  RACE  TOTCHG  APRDRG\n276    0       1    2   NaN    1156     640",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>AGE</th>\n      <th>FEMALE</th>\n      <th>LOS</th>\n      <th>RACE</th>\n      <th>TOTCHG</th>\n      <th>APRDRG</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>276</th>\n      <td>0</td>\n      <td>1</td>\n      <td>2</td>\n      <td>NaN</td>\n      <td>1156</td>\n      <td>640</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#results show that the RACE column has 1 NULL value\n",
    "#Can either DROP or SUBSTITUTE that row with a different value\n",
    "\n",
    "#here's the code to specifically identify the row with the NULL value\n",
    "hospitalCost[hospitalCost['RACE'].isnull()]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [],
   "source": [
    "#dropping row::notice the 276 from the previous command\n",
    "hospitalCost=hospitalCost.drop(labels=276, axis=0)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [],
   "source": [
    "# time for training and validation\n",
    "# using the 80-20 rule\n",
    "\n",
    "X = hospitalCost.drop(['LOS'],axis=1)\n",
    "Y = hospitalCost['LOS']"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [
    {
     "data": {
      "text/plain": "(399, 399, 100, 100)"
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Splitting data:: 80% for the training\n",
    "X_train = np.array(X[0:int(0.80 * len(X))])\n",
    "Y_train = np.array(Y[0:int(0.80*len(Y))])\n",
    "X_test = np.array(X[int(0.80*len(X)):])\n",
    "Y_test = np.array(Y[int(0.80*len(Y)):])\n",
    "len(X_train), len(Y_train), len(X_test), len(Y_test)\n",
    "\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lvngwtr/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/lvngwtr/opt/anaconda3/lib/python3.9/site-packages/sklearn/svm/_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/Users/lvngwtr/opt/anaconda3/lib/python3.9/site-packages/sklearn/neighbors/_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression is 51.000000 percent accurate\n",
      "KNN is 69.000000 percent accurate\n",
      "Naive Bayes is 27.000000 percent accurate\n",
      "Linear SVMs is 65.000000 percent accurate\n",
      "Non Linear SVMs is 52.000000 percent accurate\n",
      "Decision Trees is 66.000000 percent accurate\n",
      "Random Forests is 66.000000 percent accurate\n"
     ]
    }
   ],
   "source": [
    "# now running the ML models\n",
    "# importing algorithms\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "#initializing variables\n",
    "LR = LogisticRegression()\n",
    "KNN = KNeighborsClassifier()\n",
    "NB = GaussianNB()\n",
    "LSVM = LinearSVC()\n",
    "NLSVM = SVC(kernel='rbf')\n",
    "DT = DecisionTreeClassifier()\n",
    "RF = RandomForestClassifier()\n",
    "\n",
    "# Training data on Data Set\n",
    "LR_fit = LR.fit(X_train, Y_train)\n",
    "KNN_fit = KNN.fit(X_train, Y_train)\n",
    "NB_fit = NB.fit(X_train, Y_train)\n",
    "LSVM_fit = LSVM.fit(X_train, Y_train)\n",
    "NLSVM_fit = NLSVM.fit(X_train, Y_train)\n",
    "DT_fit = DT.fit(X_train, Y_train)\n",
    "RF_fit = RF.fit(X_train, Y_train)\n",
    "\n",
    "\n",
    "# Predicting on test data set\n",
    "LR_pred = LR_fit.predict(X_test)\n",
    "KNN_pred = KNN_fit.predict(X_test)\n",
    "NB_pred = NB_fit.predict(X_test)\n",
    "LSVM_pred = LSVM_fit.predict(X_test)\n",
    "NLSVM_pred = NLSVM_fit.predict(X_test)\n",
    "DT_pred = DT_fit.predict(X_test)\n",
    "RF_pred = RF_fit.predict(X_test)\n",
    "\n",
    "#printing accuracy of the prediction\n",
    "from sklearn.metrics import accuracy_score\n",
    "print(\"Logistic Regression is %f percent accurate\" % (accuracy_score(LR_pred, Y_test)*100))\n",
    "print(\"KNN is %f percent accurate\" % (accuracy_score(KNN_pred, Y_test)*100))\n",
    "print(\"Naive Bayes is %f percent accurate\" % (accuracy_score(NB_pred, Y_test)*100))\n",
    "print(\"Linear SVMs is %f percent accurate\" % (accuracy_score(LSVM_pred, Y_test)*100))\n",
    "print(\"Non Linear SVMs is %f percent accurate\" % (accuracy_score(NLSVM_pred, Y_test)*100))\n",
    "print(\"Decision Trees is %f percent accurate\" % (accuracy_score(DT_pred, Y_test)*100))\n",
    "print(\"Random Forests is %f percent accurate\" % (accuracy_score(RF_pred, Y_test)*100))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [],
   "source": [
    "# CROSS VALIDATION K FOLD LINEAR REGRESSION"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lvngwtr/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/lvngwtr/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/lvngwtr/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/lvngwtr/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/lvngwtr/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/lvngwtr/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_split.py:676: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=5.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score in each iteration: [0.45, 0.43, 0.41, 0.46, 0.49]\n",
      "K-Fold Score: 0.44800000000000006\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lvngwtr/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/lvngwtr/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/lvngwtr/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/lvngwtr/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score in each iteration: [0.46, 0.43, 0.44, 0.41, 0.43]\n",
      "Stratified K-Fold Score: 0.434\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lvngwtr/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import KFold\n",
    "seed=0\n",
    "cv = KFold(n_splits=5,random_state=2, shuffle=True)\n",
    "\n",
    "def return_score(model,X_train, X_test, y_train, y_test):\n",
    "    model.fit(X_train, y_train)\n",
    "    score = model.score(X_test, y_test)\n",
    "    return score\n",
    "\n",
    "scores=[]\n",
    "\n",
    "model = LogisticRegression()\n",
    "for train_index, test_index in cv.split(X,Y):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X,Y,test_size=0.2)\n",
    "    score = return_score(model,X_train, X_test, y_train, y_test)\n",
    "    scores.append(score)\n",
    "print(\"Accuracy score in each iteration: {}\".format(scores))\n",
    "print(\"K-Fold Score: {}\".format(np.mean(scores)))\n",
    "\n",
    "# CROSS VALIDATION StratifiedKFold LogisticRegression()\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "cv = StratifiedKFold(n_splits=5,random_state=2, shuffle=True)\n",
    "\n",
    "def return_score(model,X_train, X_test, y_train, y_test):\n",
    "    model.fit(X_train, y_train)\n",
    "    score = model.score(X_test, y_test)\n",
    "    return score\n",
    "\n",
    "scores=[]\n",
    "\n",
    "#printingStratefiedKFold\n",
    "model = LogisticRegression()\n",
    "for train_index, test_index in cv.split(X,Y):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X,Y,test_size=0.2)\n",
    "    score = return_score(model,X_train, X_test, y_train, y_test)\n",
    "    scores.append(score)\n",
    "print(\"Accuracy score in each iteration: {}\".format(scores))\n",
    "print(\"Stratified K-Fold Score: {}\".format(np.mean(scores)))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lvngwtr/opt/anaconda3/lib/python3.9/site-packages/sklearn/neighbors/_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n",
      "/Users/lvngwtr/opt/anaconda3/lib/python3.9/site-packages/sklearn/neighbors/_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n",
      "/Users/lvngwtr/opt/anaconda3/lib/python3.9/site-packages/sklearn/neighbors/_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n",
      "/Users/lvngwtr/opt/anaconda3/lib/python3.9/site-packages/sklearn/neighbors/_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n",
      "/Users/lvngwtr/opt/anaconda3/lib/python3.9/site-packages/sklearn/neighbors/_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n",
      "/Users/lvngwtr/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_split.py:676: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=5.\n",
      "  warnings.warn(\n",
      "/Users/lvngwtr/opt/anaconda3/lib/python3.9/site-packages/sklearn/neighbors/_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score in each iteration: [0.61, 0.62, 0.64, 0.69, 0.67]\n",
      "K-Fold Score: 0.646\n",
      "Accuracy score in each iteration: [0.66, 0.61, 0.72, 0.54, 0.62]\n",
      "Stratified K-Fold Score: 0.6300000000000001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lvngwtr/opt/anaconda3/lib/python3.9/site-packages/sklearn/neighbors/_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n",
      "/Users/lvngwtr/opt/anaconda3/lib/python3.9/site-packages/sklearn/neighbors/_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n",
      "/Users/lvngwtr/opt/anaconda3/lib/python3.9/site-packages/sklearn/neighbors/_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n",
      "/Users/lvngwtr/opt/anaconda3/lib/python3.9/site-packages/sklearn/neighbors/_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n"
     ]
    }
   ],
   "source": [
    "# CROSS VALIDATION K FOLD KNN\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import KFold\n",
    "seed=0\n",
    "cv = KFold(n_splits=5,random_state=2, shuffle=True)\n",
    "\n",
    "\n",
    "def return_score(model,X_train, X_test, y_train, y_test):\n",
    "    model.fit(X_train, y_train)\n",
    "    score = model.score(X_test, y_test)\n",
    "    return score\n",
    "\n",
    "scores=[]\n",
    "\n",
    "model = KNeighborsClassifier()\n",
    "for train_index, test_index in cv.split(X,Y):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X,Y,test_size=0.2)\n",
    "    score = return_score(model,X_train, X_test, y_train, y_test)\n",
    "    scores.append(score)\n",
    "\n",
    "print(\"Accuracy score in each iteration: {}\".format(scores))\n",
    "print(\"K-Fold Score: {}\".format(np.mean(scores)))\n",
    "\n",
    "# CROSS VALIDATION StratifiedKFold KNeighborsClassifier()\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "cv = StratifiedKFold(n_splits=5,random_state=2, shuffle=True)\n",
    "\n",
    "def return_score(model,X_train, X_test, y_train, y_test):\n",
    "    model.fit(X_train, y_train)\n",
    "    score = model.score(X_test, y_test)\n",
    "    return score\n",
    "\n",
    "scores=[]\n",
    "\n",
    "#printingStratefiedKFold\n",
    "model = KNeighborsClassifier()\n",
    "for train_index, test_index in cv.split(X,Y):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X,Y,test_size=0.2)\n",
    "    score = return_score(model,X_train, X_test, y_train, y_test)\n",
    "    scores.append(score)\n",
    "print(\"Accuracy score in each iteration: {}\".format(scores))\n",
    "print(\"Stratified K-Fold Score: {}\".format(np.mean(scores)))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score in each iteration: [0.44, 0.42, 0.41, 0.4, 0.5]\n",
      "K-Fold Score: 0.434\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lvngwtr/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_split.py:676: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=5.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score in each iteration: [0.52, 0.41, 0.49, 0.56, 0.5]\n",
      "Stratified K-Fold Score: 0.496\n"
     ]
    }
   ],
   "source": [
    "# CROSS VALIDATION K FOLD GaussianNB\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import KFold\n",
    "seed=0\n",
    "cv = KFold(n_splits=5,random_state=2, shuffle=True)\n",
    "\n",
    "def return_score(model,X_train, X_test, y_train, y_test):\n",
    "    model.fit(X_train, y_train)\n",
    "    score = model.score(X_test, y_test)\n",
    "    return score\n",
    "\n",
    "scores=[]\n",
    "\n",
    "model = GaussianNB()\n",
    "for train_index, test_index in cv.split(X,Y):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X,Y,test_size=0.2)\n",
    "    score = return_score(model,X_train, X_test, y_train, y_test)\n",
    "    scores.append(score)\n",
    "\n",
    "print(\"Accuracy score in each iteration: {}\".format(scores))\n",
    "print(\"K-Fold Score: {}\".format(np.mean(scores)))\n",
    "\n",
    "# CROSS VALIDATION StratifiedKFold GaussianNB()\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "cv = StratifiedKFold(n_splits=5,random_state=2, shuffle=True)\n",
    "\n",
    "def return_score(model,X_train, X_test, y_train, y_test):\n",
    "    model.fit(X_train, y_train)\n",
    "    score = model.score(X_test, y_test)\n",
    "    return score\n",
    "\n",
    "scores=[]\n",
    "\n",
    "#printingStratefiedKFold\n",
    "model = GaussianNB()\n",
    "for train_index, test_index in cv.split(X,Y):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X,Y,test_size=0.2)\n",
    "    score = return_score(model,X_train, X_test, y_train, y_test)\n",
    "    scores.append(score)\n",
    "print(\"Accuracy score in each iteration: {}\".format(scores))\n",
    "print(\"Stratified K-Fold Score: {}\".format(np.mean(scores)))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lvngwtr/opt/anaconda3/lib/python3.9/site-packages/sklearn/svm/_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/Users/lvngwtr/opt/anaconda3/lib/python3.9/site-packages/sklearn/svm/_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/Users/lvngwtr/opt/anaconda3/lib/python3.9/site-packages/sklearn/svm/_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/Users/lvngwtr/opt/anaconda3/lib/python3.9/site-packages/sklearn/svm/_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/Users/lvngwtr/opt/anaconda3/lib/python3.9/site-packages/sklearn/svm/_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/Users/lvngwtr/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_split.py:676: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=5.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score in each iteration: [0.23, 0.37, 0.35, 0.28, 0.23]\n",
      "K-Fold Score: 0.292\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lvngwtr/opt/anaconda3/lib/python3.9/site-packages/sklearn/svm/_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/Users/lvngwtr/opt/anaconda3/lib/python3.9/site-packages/sklearn/svm/_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/Users/lvngwtr/opt/anaconda3/lib/python3.9/site-packages/sklearn/svm/_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/Users/lvngwtr/opt/anaconda3/lib/python3.9/site-packages/sklearn/svm/_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score in each iteration: [0.48, 0.49, 0.03, 0.49, 0.1]\n",
      "Stratified K-Fold Score: 0.318\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lvngwtr/opt/anaconda3/lib/python3.9/site-packages/sklearn/svm/_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# CROSS VALIDATION K FOLD LinearSVC\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import KFold\n",
    "seed=0\n",
    "cv = KFold(n_splits=5,random_state=2, shuffle=True)\n",
    "\n",
    "def return_score(model,X_train, X_test, y_train, y_test):\n",
    "    model.fit(X_train, y_train)\n",
    "    score = model.score(X_test, y_test)\n",
    "    return score\n",
    "\n",
    "scores=[]\n",
    "\n",
    "model = LinearSVC()\n",
    "for train_index, test_index in cv.split(X,Y):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X,Y,test_size=0.2)\n",
    "    score = return_score(model,X_train, X_test, y_train, y_test)\n",
    "    scores.append(score)\n",
    "print(\"Accuracy score in each iteration: {}\".format(scores))\n",
    "print(\"K-Fold Score: {}\".format(np.mean(scores)))\n",
    "\n",
    "\n",
    "# CROSS VALIDATION StratifiedKFold LinearSVC()\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "cv = StratifiedKFold(n_splits=5,random_state=2, shuffle=True)\n",
    "\n",
    "def return_score(model,X_train, X_test, y_train, y_test):\n",
    "    model.fit(X_train, y_train)\n",
    "    score = model.score(X_test, y_test)\n",
    "    return score\n",
    "\n",
    "scores=[]\n",
    "\n",
    "#printingStratefiedKFold\n",
    "model = LinearSVC()\n",
    "for train_index, test_index in cv.split(X,Y):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X,Y,test_size=0.2)\n",
    "    score = return_score(model,X_train, X_test, y_train, y_test)\n",
    "    scores.append(score)\n",
    "print(\"Accuracy score in each iteration: {}\".format(scores))\n",
    "print(\"Stratified K-Fold Score: {}\".format(np.mean(scores)))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score in each iteration: [0.51, 0.45, 0.49, 0.49, 0.52]\n",
      "K-Fold Score: 0.492\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lvngwtr/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_split.py:676: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=5.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score in each iteration: [0.43, 0.51, 0.44, 0.48, 0.48]\n",
      "Stratified K-Fold Score: 0.46799999999999997\n"
     ]
    }
   ],
   "source": [
    "# CROSS VALIDATION K FOLD SVC\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import KFold\n",
    "seed=0\n",
    "cv = KFold(n_splits=5,random_state=2, shuffle=True)\n",
    "\n",
    "def return_score(model,X_train, X_test, y_train, y_test):\n",
    "    model.fit(X_train, y_train)\n",
    "    score = model.score(X_test, y_test)\n",
    "    return score\n",
    "\n",
    "scores=[]\n",
    "\n",
    "model = SVC(kernel='rbf')\n",
    "for train_index, test_index in cv.split(X,Y):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X,Y,test_size=0.2)\n",
    "    score = return_score(model,X_train, X_test, y_train, y_test)\n",
    "    scores.append(score)\n",
    "print(\"Accuracy score in each iteration: {}\".format(scores))\n",
    "print(\"K-Fold Score: {}\".format(np.mean(scores)))\n",
    "\n",
    "\n",
    "# CROSS VALIDATION StratifiedKFold SVC(kernel='rbf')\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "cv = StratifiedKFold(n_splits=5,random_state=2, shuffle=True)\n",
    "\n",
    "def return_score(model,X_train, X_test, y_train, y_test):\n",
    "    model.fit(X_train, y_train)\n",
    "    score = model.score(X_test, y_test)\n",
    "    return score\n",
    "\n",
    "scores=[]\n",
    "\n",
    "#printingStratefiedKFold\n",
    "model = SVC(kernel='rbf')\n",
    "for train_index, test_index in cv.split(X,Y):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X,Y,test_size=0.2)\n",
    "    score = return_score(model,X_train, X_test, y_train, y_test)\n",
    "    scores.append(score)\n",
    "print(\"Accuracy score in each iteration: {}\".format(scores))\n",
    "print(\"Stratified K-Fold Score: {}\".format(np.mean(scores)))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score in each iteration: [0.64, 0.69, 0.69, 0.59, 0.65]\n",
      "K-Fold Score: 0.6519999999999999\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lvngwtr/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_split.py:676: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=5.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score in each iteration: [0.59, 0.66, 0.73, 0.69, 0.65]\n",
      "Stratified K-Fold Score: 0.6639999999999999\n"
     ]
    }
   ],
   "source": [
    "# CROSS VALIDATION K FOLD DecisionTreeClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import KFold\n",
    "seed=0\n",
    "cv = KFold(n_splits=5,random_state=2, shuffle=True)\n",
    "\n",
    "\n",
    "def return_score(model,X_train, X_test, y_train, y_test):\n",
    "    model.fit(X_train, y_train)\n",
    "    score = model.score(X_test, y_test)\n",
    "    return score\n",
    "\n",
    "scores=[]\n",
    "\n",
    "model = DecisionTreeClassifier()\n",
    "for train_index, test_index in cv.split(X,Y):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X,Y,test_size=0.2)\n",
    "    score = return_score(model,X_train, X_test, y_train, y_test)\n",
    "    scores.append(score)\n",
    "print(\"Accuracy score in each iteration: {}\".format(scores))\n",
    "print(\"K-Fold Score: {}\".format(np.mean(scores)))\n",
    "\n",
    "\n",
    "# CROSS VALIDATION StratifiedKFold DecisionTreeClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "cv = StratifiedKFold(n_splits=5,random_state=2, shuffle=True)\n",
    "\n",
    "def return_score(model,X_train, X_test, y_train, y_test):\n",
    "    model.fit(X_train, y_train)\n",
    "    score = model.score(X_test, y_test)\n",
    "    return score\n",
    "\n",
    "scores=[]\n",
    "\n",
    "#printingStratefiedKFold\n",
    "model = DecisionTreeClassifier()\n",
    "for train_index, test_index in cv.split(X,Y):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X,Y,test_size=0.2)\n",
    "    score = return_score(model,X_train, X_test, y_train, y_test)\n",
    "    scores.append(score)\n",
    "print(\"Accuracy score in each iteration: {}\".format(scores))\n",
    "print(\"Stratified K-Fold Score: {}\".format(np.mean(scores)))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score in each iteration: [0.66, 0.64, 0.64, 0.57, 0.62]\n",
      "K-Fold Score: 0.626\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lvngwtr/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_split.py:676: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=5.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score in each iteration: [0.62, 0.68, 0.59, 0.61, 0.63]\n",
      "Stratified K-Fold Score: 0.626\n"
     ]
    }
   ],
   "source": [
    "# CROSS VALIDATION K FOLD RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import KFold\n",
    "seed=0\n",
    "cv = KFold(n_splits=5,random_state=2, shuffle=True)\n",
    "\n",
    "def return_score(model,X_train, X_test, y_train, y_test):\n",
    "    model.fit(X_train, y_train)\n",
    "    score = model.score(X_test, y_test)\n",
    "    return score\n",
    "\n",
    "scores=[]\n",
    "\n",
    "#printing Kfold\n",
    "model = RandomForestClassifier()\n",
    "for train_index, test_index in cv.split(X,Y):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X,Y,test_size=0.2)\n",
    "    score = return_score(model,X_train, X_test, y_train, y_test)\n",
    "    scores.append(score)\n",
    "print(\"Accuracy score in each iteration: {}\".format(scores))\n",
    "print(\"K-Fold Score: {}\".format(np.mean(scores)))\n",
    "\n",
    "\n",
    "# CROSS VALIDATION StratifiedKFold RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "cv = StratifiedKFold(n_splits=5,random_state=2, shuffle=True)\n",
    "\n",
    "def return_score(model,X_train, X_test, y_train, y_test):\n",
    "    model.fit(X_train, y_train)\n",
    "    score = model.score(X_test, y_test)\n",
    "    return score\n",
    "\n",
    "scores=[]\n",
    "\n",
    "#printingStratefiedKFold\n",
    "model = RandomForestClassifier()\n",
    "for train_index, test_index in cv.split(X,Y):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X,Y,test_size=0.2)\n",
    "    score = return_score(model,X_train, X_test, y_train, y_test)\n",
    "    scores.append(score)\n",
    "print(\"Accuracy score in each iteration: {}\".format(scores))\n",
    "print(\"Stratified K-Fold Score: {}\".format(np.mean(scores)))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
