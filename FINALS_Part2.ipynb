{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Supress warnings:\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "data": {
      "text/plain": "   ID  Age  Gender  Height  Weight   BMI          Label\n0   1   25    Male     175      80  25.3  Normal Weight\n1   2   30  Female     160      60  22.5  Normal Weight\n2   3   35    Male     180      90  27.3     Overweight\n3   4   40  Female     150      50  20.0    Underweight\n4   5   45    Male     190     100  31.2          Obese",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>ID</th>\n      <th>Age</th>\n      <th>Gender</th>\n      <th>Height</th>\n      <th>Weight</th>\n      <th>BMI</th>\n      <th>Label</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>25</td>\n      <td>Male</td>\n      <td>175</td>\n      <td>80</td>\n      <td>25.3</td>\n      <td>Normal Weight</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2</td>\n      <td>30</td>\n      <td>Female</td>\n      <td>160</td>\n      <td>60</td>\n      <td>22.5</td>\n      <td>Normal Weight</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>3</td>\n      <td>35</td>\n      <td>Male</td>\n      <td>180</td>\n      <td>90</td>\n      <td>27.3</td>\n      <td>Overweight</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>4</td>\n      <td>40</td>\n      <td>Female</td>\n      <td>150</td>\n      <td>50</td>\n      <td>20.0</td>\n      <td>Underweight</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>5</td>\n      <td>45</td>\n      <td>Male</td>\n      <td>190</td>\n      <td>100</td>\n      <td>31.2</td>\n      <td>Obese</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#loading data\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "file_path = Path(\"obesityData/Obesity Classification.csv\")\n",
    "obesity = pd.read_csv(file_path)\n",
    "\n",
    "#first 5 records\n",
    "obesity.head()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "data": {
      "text/plain": "      ID  Age  Gender  Height  Weight  BMI        Label\n103  106   11    Male     175      10  3.9  Underweight\n104  107   16  Female     160      10  3.9  Underweight\n105  108   21    Male     180      15  5.6  Underweight\n106  109   26  Female     150      15  5.6  Underweight\n107  110   31    Male     190      20  8.3  Underweight",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>ID</th>\n      <th>Age</th>\n      <th>Gender</th>\n      <th>Height</th>\n      <th>Weight</th>\n      <th>BMI</th>\n      <th>Label</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>103</th>\n      <td>106</td>\n      <td>11</td>\n      <td>Male</td>\n      <td>175</td>\n      <td>10</td>\n      <td>3.9</td>\n      <td>Underweight</td>\n    </tr>\n    <tr>\n      <th>104</th>\n      <td>107</td>\n      <td>16</td>\n      <td>Female</td>\n      <td>160</td>\n      <td>10</td>\n      <td>3.9</td>\n      <td>Underweight</td>\n    </tr>\n    <tr>\n      <th>105</th>\n      <td>108</td>\n      <td>21</td>\n      <td>Male</td>\n      <td>180</td>\n      <td>15</td>\n      <td>5.6</td>\n      <td>Underweight</td>\n    </tr>\n    <tr>\n      <th>106</th>\n      <td>109</td>\n      <td>26</td>\n      <td>Female</td>\n      <td>150</td>\n      <td>15</td>\n      <td>5.6</td>\n      <td>Underweight</td>\n    </tr>\n    <tr>\n      <th>107</th>\n      <td>110</td>\n      <td>31</td>\n      <td>Male</td>\n      <td>190</td>\n      <td>20</td>\n      <td>8.3</td>\n      <td>Underweight</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#verifying last records\n",
    "obesity.tail()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "data": {
      "text/plain": "   Age  Gender  Height  Weight   BMI          Label\n0   25    Male     175      80  25.3  Normal Weight\n1   30  Female     160      60  22.5  Normal Weight\n2   35    Male     180      90  27.3     Overweight\n3   40  Female     150      50  20.0    Underweight\n4   45    Male     190     100  31.2          Obese",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Age</th>\n      <th>Gender</th>\n      <th>Height</th>\n      <th>Weight</th>\n      <th>BMI</th>\n      <th>Label</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>25</td>\n      <td>Male</td>\n      <td>175</td>\n      <td>80</td>\n      <td>25.3</td>\n      <td>Normal Weight</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>30</td>\n      <td>Female</td>\n      <td>160</td>\n      <td>60</td>\n      <td>22.5</td>\n      <td>Normal Weight</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>35</td>\n      <td>Male</td>\n      <td>180</td>\n      <td>90</td>\n      <td>27.3</td>\n      <td>Overweight</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>40</td>\n      <td>Female</td>\n      <td>150</td>\n      <td>50</td>\n      <td>20.0</td>\n      <td>Underweight</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>45</td>\n      <td>Male</td>\n      <td>190</td>\n      <td>100</td>\n      <td>31.2</td>\n      <td>Obese</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#dropping irrelevant column/s\n",
    "columns_to_drop = ['ID']\n",
    "\n",
    "obesity.drop(columns=columns_to_drop, axis=1, inplace=True)\n",
    "obesity.head()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gender Encoder Classes:\n",
      "Female: 0\n",
      "Male: 1\n"
     ]
    },
    {
     "data": {
      "text/plain": "   Age  Gender  Height  Weight   BMI          Label\n0   25       1     175      80  25.3  Normal Weight\n1   30       0     160      60  22.5  Normal Weight\n2   35       1     180      90  27.3     Overweight\n3   40       0     150      50  20.0    Underweight\n4   45       1     190     100  31.2          Obese",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Age</th>\n      <th>Gender</th>\n      <th>Height</th>\n      <th>Weight</th>\n      <th>BMI</th>\n      <th>Label</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>25</td>\n      <td>1</td>\n      <td>175</td>\n      <td>80</td>\n      <td>25.3</td>\n      <td>Normal Weight</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>30</td>\n      <td>0</td>\n      <td>160</td>\n      <td>60</td>\n      <td>22.5</td>\n      <td>Normal Weight</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>35</td>\n      <td>1</td>\n      <td>180</td>\n      <td>90</td>\n      <td>27.3</td>\n      <td>Overweight</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>40</td>\n      <td>0</td>\n      <td>150</td>\n      <td>50</td>\n      <td>20.0</td>\n      <td>Underweight</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>45</td>\n      <td>1</td>\n      <td>190</td>\n      <td>100</td>\n      <td>31.2</td>\n      <td>Obese</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#replacing Gender column with numerical labels for algorithm\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Create a LabelEncoder object for the \"Gender\" column\n",
    "le_gender = LabelEncoder()\n",
    "# Encode the \"Gender\" column\n",
    "obesity['Gender'] = le_gender.fit_transform(obesity['Gender'])\n",
    "\n",
    "print(\"Gender Encoder Classes:\")\n",
    "for gender, encoded_gender in zip(le_gender.classes_, le_gender.transform(le_gender.classes_)):\n",
    "    # print original gender labels and the encoded values\n",
    "    print(f\"{gender}: {encoded_gender}\")  # Print the gender label and its encoded value\n",
    "\n",
    "\n",
    "obesity.head()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "data": {
      "text/plain": "Age       0\nGender    0\nHeight    0\nWeight    0\nBMI       0\nLabel     0\ndtype: int64"
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#checking for null values\n",
    "obesity.isnull().sum()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Manually Assigned Encoder:\n",
      "Normal Weight: 0\n",
      "Overweight: 1\n",
      "Obese: 2\n",
      "Underweight: 3\n"
     ]
    },
    {
     "data": {
      "text/plain": "   Age  Gender  Height  Weight   BMI  Label\n0   25       1     175      80  25.3      0\n1   30       0     160      60  22.5      0\n2   35       1     180      90  27.3      1\n3   40       0     150      50  20.0      3\n4   45       1     190     100  31.2      2",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Age</th>\n      <th>Gender</th>\n      <th>Height</th>\n      <th>Weight</th>\n      <th>BMI</th>\n      <th>Label</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>25</td>\n      <td>1</td>\n      <td>175</td>\n      <td>80</td>\n      <td>25.3</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>30</td>\n      <td>0</td>\n      <td>160</td>\n      <td>60</td>\n      <td>22.5</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>35</td>\n      <td>1</td>\n      <td>180</td>\n      <td>90</td>\n      <td>27.3</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>40</td>\n      <td>0</td>\n      <td>150</td>\n      <td>50</td>\n      <td>20.0</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>45</td>\n      <td>1</td>\n      <td>190</td>\n      <td>100</td>\n      <td>31.2</td>\n      <td>2</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# manually replacing Label column with numerical labels for algorithm\n",
    "\n",
    "label_mapping = {\n",
    "    \"Normal Weight\": 0,\n",
    "    \"Overweight\": 1,\n",
    "    \"Obese\": 2,\n",
    "    \"Underweight\": 3\n",
    "}\n",
    "# Manually assigning the encoder using the label mapping\n",
    "obesity['Label'] = obesity['Label'].map(label_mapping)\n",
    "\n",
    "print(\"Manually Assigned Encoder:\")\n",
    "for label, encoded_label in label_mapping.items():\n",
    "    # # Print the original label and its corresponding encoded value\n",
    "    print(f\"{label}: {encoded_label}\")\n",
    "\n",
    "\n",
    "obesity.head()\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The size of training input is (86, 5)\n",
      "The size of training output is (86,)\n",
      "**************************************************\n",
      "The size of testing input is (22, 5)\n",
      "The size of testing output is (22,)\n"
     ]
    }
   ],
   "source": [
    "#import NumPy library\n",
    "import numpy as np\n",
    "\n",
    "#data partition by LABEL (Dependent variable)\n",
    "X = obesity.drop(['Label'], axis=1)\n",
    "Y = obesity['Label']\n",
    "\n",
    "# Taking 80% of House data as training set, and remaining 20% as test set.\n",
    "X_train = np.array(X[0:int(0.80*len(X))])\n",
    "Y_train = np.array(Y[0:int(0.80*len(Y))])\n",
    "X_test = np.array(X[int(0.80*len(X)):])\n",
    "Y_test = np.array(Y[int(0.80*len(Y)):])\n",
    "len(X_train), len(Y_train), len(X_test), len(Y_test)\n",
    "\n",
    "print(\"The size of training input is\", X_train.shape)\n",
    "print(\"The size of training output is\", Y_train.shape)\n",
    "print(50 *'*')\n",
    "print(\"The size of testing input is\", X_test.shape)\n",
    "print(\"The size of testing output is\", Y_test.shape)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression is 95.454545 percent accurate\n",
      "KNN is 90.909091 percent accurate\n",
      "Naive Bayes is 95.454545 percent accurate\n",
      "Linear SVMs is 95.454545 percent accurate\n",
      "Non Linear SVMs is 95.454545 percent accurate\n",
      "Decision Trees is 100.000000 percent accurate\n",
      "Random Forests is 100.000000 percent accurate\n",
      "Elapsed time: 0.03 minutes\n"
     ]
    }
   ],
   "source": [
    "#measuring initial execution time\n",
    "import time\n",
    "start_time = time.time()\n",
    "\n",
    "#****ALL ML ALGORITHMS*****\n",
    "\n",
    "#importing algorithms\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "#initializing variables\n",
    "LR = LogisticRegression()\n",
    "KNN = KNeighborsClassifier()\n",
    "NB = GaussianNB()\n",
    "LSVM = LinearSVC()\n",
    "NLSVM = SVC(kernel='rbf')\n",
    "DT = DecisionTreeClassifier()\n",
    "RF = RandomForestClassifier()\n",
    "\n",
    "# Training data on Data Set\n",
    "LR_fit = LR.fit(X_train, Y_train)\n",
    "KNN_fit = KNN.fit(X_train, Y_train)\n",
    "NB_fit = NB.fit(X_train, Y_train)\n",
    "LSVM_fit = LSVM.fit(X_train, Y_train)\n",
    "NLSVM_fit = NLSVM.fit(X_train, Y_train)\n",
    "DT_fit = DT.fit(X_train, Y_train)\n",
    "RF_fit = RF.fit(X_train, Y_train)\n",
    "\n",
    "\n",
    "# Predicting on test data set\n",
    "LR_pred = LR_fit.predict(X_test)\n",
    "KNN_pred = KNN_fit.predict(X_test)\n",
    "NB_pred = NB_fit.predict(X_test)\n",
    "LSVM_pred = LSVM_fit.predict(X_test)\n",
    "NLSVM_pred = NLSVM_fit.predict(X_test)\n",
    "DT_pred = DT_fit.predict(X_test)\n",
    "RF_pred = RF_fit.predict(X_test)\n",
    "\n",
    "#printing accuracy of the prediction\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "print(\"Logistic Regression is %f percent accurate\" % (accuracy_score(LR_pred, Y_test)*100))\n",
    "print(\"KNN is %f percent accurate\" % (accuracy_score(KNN_pred, Y_test)*100))\n",
    "print(\"Naive Bayes is %f percent accurate\" % (accuracy_score(NB_pred, Y_test)*100))\n",
    "print(\"Linear SVMs is %f percent accurate\" % (accuracy_score(LSVM_pred, Y_test)*100))\n",
    "print(\"Non Linear SVMs is %f percent accurate\" % (accuracy_score(NLSVM_pred, Y_test)*100))\n",
    "print(\"Decision Trees is %f percent accurate\" % (accuracy_score(DT_pred, Y_test)*100))\n",
    "print(\"Random Forests is %f percent accurate\" % (accuracy_score(RF_pred, Y_test)*100))\n",
    "\n",
    "#measuring final execution time\n",
    "end_time = time.time()\n",
    "\n",
    "elapsed_time = end_time - start_time\n",
    "elapsed_minutes = elapsed_time / 60\n",
    "\n",
    "print(\"Elapsed time: %.2f minutes\" % elapsed_minutes)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tabulate in /Users/lvngwtr/opt/anaconda3/lib/python3.9/site-packages (0.8.10)\r\n",
      "+------------------------+----------------+---------------------------+\n",
      "| Model                  |   K-Fold Score |   Stratified K-Fold Score |\n",
      "+========================+================+===========================+\n",
      "| LogisticRegression     |         0.7562 |                    0.7431 |\n",
      "+------------------------+----------------+---------------------------+\n",
      "| KNeighborsClassifier   |         0.8124 |                    0.8261 |\n",
      "+------------------------+----------------+---------------------------+\n",
      "| GaussianNB             |         0.9078 |                    0.8837 |\n",
      "+------------------------+----------------+---------------------------+\n",
      "| LinearSVC              |         0.6752 |                    0.6046 |\n",
      "+------------------------+----------------+---------------------------+\n",
      "| SVC                    |         0.6967 |                    0.7562 |\n",
      "+------------------------+----------------+---------------------------+\n",
      "| DecisionTreeClassifier |         0.9301 |                    0.9529 |\n",
      "+------------------------+----------------+---------------------------+\n",
      "| RandomForestClassifier |         0.9765 |                    0.9765 |\n",
      "+------------------------+----------------+---------------------------+\n"
     ]
    }
   ],
   "source": [
    "!pip install tabulate\n",
    "from sklearn.model_selection import train_test_split, KFold, StratifiedKFold\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.svm import LinearSVC, SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import numpy as np\n",
    "from tabulate import tabulate\n",
    "\n",
    "seed = 0\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=seed)\n",
    "\n",
    "# KFold cross-validation with various models\n",
    "kf = KFold(n_splits=5, random_state=2, shuffle=True)\n",
    "kfold_scores = []\n",
    "\n",
    "for model in [LogisticRegression(), KNeighborsClassifier(), GaussianNB(), LinearSVC(), SVC(kernel='rbf'), DecisionTreeClassifier(), RandomForestClassifier()]:\n",
    "    scores = []\n",
    "    for train_index, test_index in kf.split(X_train):\n",
    "        model.fit(X_train.iloc[train_index], Y_train.iloc[train_index])\n",
    "        score = model.score(X_train.iloc[test_index], Y_train.iloc[test_index])\n",
    "        scores.append(score)\n",
    "\n",
    "    kfold_scores.append([type(model).__name__, np.mean(scores)])\n",
    "\n",
    "\n",
    "# StratifiedKFold cross-validation with various models\n",
    "skf = StratifiedKFold(n_splits=5, random_state=2, shuffle=True)\n",
    "stratified_kfold_scores = []\n",
    "\n",
    "for model in [LogisticRegression(), KNeighborsClassifier(), GaussianNB(), LinearSVC(), SVC(kernel='rbf'), DecisionTreeClassifier(), RandomForestClassifier()]:\n",
    "    scores = []\n",
    "    for train_index, test_index in skf.split(X_train, Y_train):\n",
    "        model.fit(X_train.iloc[train_index], Y_train.iloc[train_index])\n",
    "        score = model.score(X_train.iloc[test_index], Y_train.iloc[test_index])\n",
    "        scores.append(score)\n",
    "\n",
    "    stratified_kfold_scores.append([type(model).__name__, np.mean(scores)])\n",
    "\n",
    "\n",
    "# Print the scores in a table\n",
    "table_headers = [\"Model\", \"K-Fold Score\", \"Stratified K-Fold Score\"]\n",
    "table_data = []\n",
    "\n",
    "for kfold_score, stratified_kfold_score in zip(kfold_scores, stratified_kfold_scores):\n",
    "    model_name = kfold_score[0]\n",
    "    kfold_score_val = kfold_score[1]\n",
    "    stratified_kfold_score_val = stratified_kfold_score[1]\n",
    "    table_data.append([model_name, kfold_score_val, stratified_kfold_score_val])\n",
    "\n",
    "table = tabulate(table_data, headers=table_headers, floatfmt=\".4f\", tablefmt=\"grid\")\n",
    "print(table)\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [
    "#@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@\n",
    "# The dependent variable is the outcome or the target variable we try to predict or classify based on the independent variables. Therefore, in the given Obesity dataset, the dependent column is the \"Label\" column, which represents the obesity classification of each individual.\n",
    "#\n",
    "# The independent columns in the dataset are;\n",
    "# ID: A unique identifier for each individual. This column serves as an identifier and provides no meaningful information for predicting the obesity classification.\n",
    "# Age: The age of the individual. It is a continuous variable that can be relevant in determining obesity classification.\n",
    "# Gender: The gender of the individual. It is a categorical variable and can be considered an independent variable for predicting obesity.\n",
    "#     Height: The height of the individual in centimeters. It is a continuous variable that can be used as an independent variable to predict obesity.\n",
    "# Weight: The weight of the individual in kilograms. It is a continuous variable that can be used as an independent variable to predict obesity.\n",
    "# BMI: The individual's body mass index, calculated as weight divided by height squared. It is a continuous variable and can be considered an independent variable for predicting obesity.\n",
    "#\n",
    "# To summarize, the dependent column is \"Label\" (obesity classification), and the independent columns are \"Age,\" \"Gender,\" \"Height,\" \"Weight,\" and \"BMI.\" I used these independent variables to build the predictive model that classifies individuals into different obesity categories.\n",
    "#\n",
    "# @@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@\n",
    "# Here are my steps for data cleaning for the given dataset:\n",
    "#\n",
    "# Handling Missing/Null Values: The dataset had no missing values. If there were, options include removing rows with missing values and filling in missing values with the mean or median.\n",
    "# Handling Outliers: No outliers exist in the numerical columns (Age, Height, Weight, and BMI). I recommend removing outliers or applying appropriate transformations to mitigate their effects.\n",
    "# Data Type Conversion: Check the data types of the columns. Ensure that they are correctly assigned. Example, the ID column should be of a numerical type float or int, while Gender and Label columns should be categorical.\n",
    "# Encoding Categorical Variables: Since Gender and Label columns are categorical variables, I encoded them into numerical values for analysis and modeling.\n",
    "# Removing Unnecessary Columns: Reviewed the dataset and identified any columns that may not be relevant to the analysis or modeling task. Thereby removing the ID column to simplify the dataset and reduce noise.\n",
    "# Handling Duplicates: Checked to remove any duplicate rows in the dataset.\n",
    "# Data Validation and Sanity Checks: I performed sanity checks on the data to identify any inconsistencies/errors. I checked that some BMI values are correctly calculated based on Height and Weight. To help validate the range and logical relationships between columns/variables.\n",
    "#\n",
    "#\n",
    "# @@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@\n",
    "# **RESULTS**(after 4 runs)\n",
    "# My above table displays the K-Fold and Stratified K-Fold scores for each model. Here are some observations based on the results:\n",
    "#\n",
    "# 1. Logistic Regression achieves a K-Fold score of 0.7562 and a slightly lower Stratified K-Fold score of 0.7431.\n",
    "#\n",
    "# 2. K-Nearest Neighbors (KNN) Classifier performs well with a K-Fold score of 0.8124 and a higher Stratified K-Fold score of 0.8261.\n",
    "#\n",
    "# 3. Gaussian Naive Bayes shows good performance with a high K-Fold score of 0.9078 and a slightly lower Stratified K-Fold score of 0.8837.\n",
    "#\n",
    "# 4. Linear Support Vector Classifier (LinearSVC) achieves a K-Fold score of 0.6379, indicating moderate performance, and a lower Stratified K-Fold score of 0.5935.\n",
    "#\n",
    "# 5. Support Vector Classifier (SVC) has a K-Fold score of 0.6967 and a higher Stratified K-Fold score of 0.7562.\n",
    "#\n",
    "# 6. Decision Tree Classifier performs well, showing high accuracy with a K-Fold score of 0.9183 and an even higher Stratified K-Fold score of 0.9412.\n",
    "#\n",
    "# 7. Random Forest Classifier achieves the highest accuracy among all models, with a K-Fold score of 0.9882 and a slightly lower Stratified K-Fold score of 0.9765.\n",
    "#\n",
    "# Based on these results, the Random Forest Classifier performs exceptionally well on the dataset, followed by the Decision Tree Classifier and Gaussian Naive Bayes. However, it's important to note that these scores are based on a smaller dataset than our other labs, so we may need to provide more diverse examples for our ML models to learn complex patterns and generalize well."
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
